---
layout: article
title: Academia
permalink: /articles/academia
---

<div markdown="1">

## Misconduct, Mistakes, and Retractions in Academia

**Misconduct, mistakes, and retractions are common within academia, although getting precise estimates for its prevalence is difficult. Misconduct appears to be rising significantly, although it is not clear whether this is due to improved screening practices or changes in the number of publications which have research containing misconduct. Higher journal impact factor is positively associated with misconduct as well, although again it is not clear whether this is a screening issue or a publication quality issue. Much of this fraud appears to be deliberately done. Luckily, retractions which occur as a consequence of misconduct result in the author of the publication getting fewer citations in the future, suggesting there is a degree of self-correction which occurs in academia dealing with this. There are a variety of reasons why misconduct occurs. Much of this research suggests that academia can be fallible in this domain.**

[How Many Scientists Fabricate and Falsify Research? A Systematic Review and Meta-Analysis of Survey Data](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0005738)

-   Meta-analysis and systematic review

-   Finds that 1.97% of scientists admit to have fabricated, falsified, or modified data or results at least once

-   Up to 33.7% admitted other questionable research practices

-   Misconduct was reported more frequently by medical/pharmacological researchers than others.

[Quotation errors in general science journals](https://sci-hub.hkvisa.net/10.1098/rspa.2020.0538)

-   Looks at 250 random citations in high-impact general science journals

-   Finds a quotation error rate of 25%

-   This result is similar with that of other studies studying similar fields

[Misconduct accounts for the majority of retracted scientific publications](https://sci-hub.ru/https://doi.org/10.1073/pnas.1212247109)

-   Review of all 2047 retracted biomedical and life-science research articles indexed as retracted by PubMed on a specific day

-   Only 21.3% of retractions were attributable to error

-   67.4% were attributable to misconduct, including fraud or suspected fraud (43.4%), duplicate publication (14.2%) and plagiarism (9.8%)

-   Percentage of scientific articles retracted due to fraud has increased tenfold since 1975

[Retractions in the scientific literature: is the incidence of research fraud increasing?](https://sci-hub.ru/https://doi.org/10.1136/jme.2010.040923)

-   Finds 26.6% of retracted English language research papers examined were retracted for fraud

-   Levels of misconduct appear to be increasing, this could be due to fraud increasing or more policing efforts of the literature to detect fraud

[Research Misconduct---Definitions, Manifestations and Extent](https://www.mdpi.com/2304-6775/1/3/87)

-   Around 0.01% of publications according to multiple studies have been found to have misconduct involved

-   However, some doubt this as it is only those which are confirmed to be misconduct counted in estimates. There are many instances which may not be detected, or where intent is not proven to be malicious, or where the instance is not documented

[The Retraction Penalty: Evidence from the Web of Science](https://www.nature.com/articles/srep03146)

-   A single retraction is found to result in substantial falls in citations for the author's prior body of work

-   However, this effect disappears when authors self-report the error

[Retracted science and the retraction index](https://sci-hub.ru/https://doi.org/10.1128/IAI.05661-11)

-   Higher journal impact factor is correlated with more retractions

-   This could be due to more risk-taking done by researchers who wish to publish in more well-known journals, or the desire of high-impact journals to have clear and definitive results could create incentives for misconduct, or there are just better screening processes.

[Retractions in the scientific literature: do authors deliberately commit research fraud?](https://sci-hub.ru/https://doi.org/10.1136/jme.2010.038125)

-   Many publications which are retracted were authored by repeat offenders, suggesting authors do deliberately commit research fraud

[Causal factors implicated in research misconduct: Evidence from ORI case files](https://sci-hub.ru/https://doi.org/10.1007/s11948-007-9045-2)

-   Analysis of themes from closed case files then analyzed through cluster analysis revealed multiple themes for causes of research misconduct, including personal and professional stressors, organizational climate, job insecurities, rationalizations, personal inhibitions, and personality factors

Further Information:

[Duplicate and fake publications in the scientific literature: how many SCIgen papers in computer science?](https://link.springer.com/article/10.1007/s11192-012-0781-y)

[Academic Misconduct and Values: The Department's Influence](https://sci-hub.se/https://doi.org/10.1353/rhe.1995.0007) (LOOK INTO LATER)

## Political Leanings of Academics

**Academics lean overwhelmingly left today, although in the past it has been more balanced. This is partially due to differences in intelligence and openness to experience, although this cannot explain all of it. Part of it is also due to self-selection, a hostile climate for right-wingers, and discrimination of right-wingers. Viewpoint diversity promotes creativity, discovery, and problem-solving, while viewpoint homogeneity promotes confirmation bias and conformity, so having more of a balance of viewpoints will help progress social science. However, it does not appear that this will affect the political orientation of students, who's political ideology doesn't change with faculty ideology and instead reflects trends of the broader population in their age group.**

[Faculty Voter Registration in Economics, History, Journalism, Law, and Psychology](https://econjwatch.org/articles/faculty-voter-registration-in-economics-history-journalism-communications-law-and-psychology)

-   Finds that there are overwhelming democrat:republican voter ratios in a variety of social science disciplines

-   Moreover, the ratio is highest in the most prestigious departments.

[How politically diverse are the social sciences and humanities? Survey evidence from six fields](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.120.9897&rep=rep1&type=pdf)

-   In the social sciences and humanities, faculty are heavily skewed towards being democratic over republican

[Political diversity will improve social psychological science](https://sci-hub.hkvisa.net/10.1017/s0140525x15000035)

-   Diversity of viewpoints enhances creativity, discovery, and problem-solving, and political diversity is lacking in social psychology.

-   This is a new phenomenon which occurred over the last 50 years, and can result in the embedding of liberal values into research, promoting confirmation bias

-   The underrepresentation of non-liberals appears to be due to a combination of self-selection, hostile climate, and discrimination

[LACKADEMIA: WHY DO ACADEMICS LEAN LEFT?](https://www.adamsmith.org/research/lackademia-why-do-academics-lean-left)

-   Left skew of academia cannot be primarily explained by intelligence, although may be partly explained by openness to experience

-   There are some other notable and plausible explanations:

-   Typing of academia as left-leaning, which pushes non-leftists out of academia

-   Pressures to conform to the prevailing ideology

-   Non-conformity on the part of academics going against the reality that they are paid less than those of their intelligence level in other areas

-   There is evidence that left-leaning academics are willing to discriminate against conservatives and that conservatives which are in academia are significantly more cited and productive than their leftist counterparts, suggesting that they are held to a higher standard.

[Indoctrination U.? Faculty Ideology and Changes in Student Political Orientation](https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/abs/indoctrination-u-faculty-ideology-and-changes-in-student-political-orientation/25ABD9B1A3577F27B5659941CD52D6C9)

-   While student political ideology changes during their course in university, it does not appear to change on the basis of faculty ideology and is consistent with the general population in their age range.

[Political Bias in the Social Sciences: A Critical, Theoretical, and Empirical Review](https://psyarxiv.com/qpn57/)

-   Literature review

-   There is an overwhelmingly left skew in academia

-   Political bias of researchers is not necessarily bad when it is counterbalanced by differing political views of different researchers, but when there is an overwhelming skew in one direction it can produce biased results

-   It is not clear what the threshold for ideological diversity is to ensure Mertonian skepticism, although wherever that line is it is clear it has been passed

-   One significant argument that normal academic processes protect political biases is that political leaning of an article has no relationship with its replicability

-   However, education and scientific literacy increase polarization on controversial science topics presumably because people look for evidence that bolsters what they already believe

-   Moreover, there are a wide variety of issues identified in the social sciences, including the replication crisis.

-   Peer review is also unreliable, it does not insure against poor or biased science

-   Merton's norms of science may be touted, although it's not obvious that they're actually practiced. For example, the fusion of activism with scientific investigation and the statement that certain publications are "harmful" violates the disinterestedness norm

-   Universalism is violated when "lived experiences" of minority groups are given precedence

-   The study on political leaning and replicability ignores how political bias isn't argued to be in that domain, but rather in methods, interpretation, citation, and canonization

-   Authors of this review believe the conclusion of the study is probably valid, but the study is too biased to actually demonstrate it, for a variety of reasons discussed

-   This paper presents two complimentary models on political bias in academia:

-   Pipeline - Left-leaning activists select into academia and make the space more hostile to non-leftists, purging those with different views. 

-   Research suggests many academics endorse discriminating against their political opponents, which can contribute to this. 

-   Disproportionate faculty awards go to those on the left, even controlling for achievements, primarily publications. 

-   Targeting sanctions initiated by scholars and graduate students are overwhelmingly initiated by the left. 

-   Many academics openly declate hostility to conservatives. 

-   Thus, the belief among conservative professors that leaking their politics risks harming their careers is likely correct. 

-   Left-wing authoritarianism is psychologically characterized by three things: intolerance, censorship, and aggression, all directed at one's political opponents

-   This can manifest as social vigilanteism

-   Given that academia is overwhelmingly left-leaning, it is likely that this is relatively prevalent in academia even if high scores of left-wing authoritarianism are uncommon in the general population.

-   Success in academia depends on approval from others, meaning that left-wing academia can be self-perpetuating

-   If the social sciences are dominated by a left-leaning bias, it can appear much more objective than it actually is to an outsider

-   Therefore, even when hundreds of studies say the same thing, because of the erosion of Mertonian norms it can still fail to justify the conclusion those studies reach

-   Wheel model - Political bias manifests in the scientific enterprise to undercut validity and credibility

-   This is done through manipulation of questions asked, measurement, interpretations, what gets cited, canonization, suppression, and discrimination

-   It does not seem likely that anything can meaningfully be done about all of this, as many major professional psychology organizations appear to support activism at this point in time

Further Information:

[Partisan Registration and Contributions of Faculty in Flagship Colleges](https://www.nas.org/blogs/article/partisan-registration-and-contributions-of-faculty-in-flagship-colleges)

[Homogenous: The Political Affiliations of Elite Liberal Arts College Faculty](https://www.nas.org/academic-questions/31/2/homogenous_the_political_affiliations_of_elite_liberal_arts_college_faculty)

[A Model of Political Bias in Social Science Research](https://sites.rutgers.edu/lee-jussim/wp-content/uploads/sites/135/2020/04/Honeycutt-Jussim-2020-A-Model-of-Political-Bias-in-Social-Science-Research.pdf)

[Without Contraries is no Progression](https://www.tandfonline.com/doi/abs/10.1080/1047840X.2020.1724725)

[Normative dissonance in science: Results from a national survey of US scientists](https://sci-hub.ru/https://doi.org/10.1525/jer.2007.2.4.3)

["Soft" versus "hard" psychological science: Biased evaluations of scientific evidence that threatens or supports a strongly held political identity](https://sci-hub.ru/https://doi.org/10.1080/01973533.2014.960080)

[Science is not always "self-correcting](https://sci-hub.ru/https://doi.org/10.1007/s10699-015-9421-3)

[Do Ideologically Driven Scientific Agendas Impede the Understanding and Acceptance of Evolutionary Principles in Social Psychology?](https://www.researchgate.net/publication/333961974_Do_Ideologically_Driven_Scientific_Agendas_Impede_the_Understanding_and_Acceptance_of_Evolutionary_Principles_in_Social_Psychology)

## Replicability in Science

**There exists a replicability crisis in science, particularly in the social sciences. Still, replicability varies between subsets of the social sciences. The degree to which a publication or finding is replicable can in fact be predicted well by scientists, but are published by journals because they are more interesting. Journal prestige in fact is negatively correlated to replicability. This appears to be due to intense competition and time pressure.**

[Estimating the reproducibility of psychological science](https://www.science.org/doi/10.1126/science.aac4716)

[Evaluating replicability of laboratory experiments in economics](https://www.science.org/doi/10.1126/science.aaf0918)

[Estimating the Reproducibility of Experimental Philosophy](https://www.researchgate.net/publication/325216701_Estimating_the_Reproducibility_of_Experimental_Philosophy)

-   Finds low replicability of findings in the social sciences

[Nonreplicable publications are cited more than replicable ones](https://sci-hub.ru/https://doi.org/10.1126/sciadv.abd1705)

-   Nonreplicable publications are cited more than replicable ones

-   The degree to which a publication is replicable can be predicted well by scientists

-   Journals likely publish nonreplicable findings because they are more interesting

-   This potentially also explains why they are cited more

[Effect Sizes, Power, and Biases in Intelligence Research: A Meta-Meta-Analysis](https://psyarxiv.com/ytsvw)

-   Intelligence research shows signs of low power and publication bias, but less so than many other scientific fields

[Low statistical power in biomedical science: a review of three human research domains](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5367316/pdf/rsos160254.pdf)

-   Studies in the biomedical sciences tend to have low statistical power

[Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature](https://journals.plos.org/plosbiology/article/file?id=10.1371/journal.pbio.2000797&type=printable)

-   There is a low replication in psychology and neuroscience

-   Journal impact factor is negatively correlated with study power

[Prestigious science journals struggle to reach even average reliability](https://sci-hub.ru/https://doi.org/10.3389/fnhum.2018.00037)

-   Research suggests that journal rank is negatively associated with the reliability of research findings.

-   This can erode trust in science over time

[Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015](https://sci-hub.se/https://doi.org/10.1038/s41562-018-0399-z)

-   There is poor reproducibility of social science experiments

-   However, peer beliefs of replicability are strongly related to actual replicability, suggesting academics can predict which results are replicable.

[Reproducibility crisis](https://sci-hub.ru/https://doi.org/10.1038/533452a)

-   The vast majority of researchers believe there is a reproducibility crisis

-   Most researchers in a variety of fields have experienced failure to reproduce results

-   Many top rated factors which contribute to it relate to intense competition and time pressure

-   Although only a small proportion of researchers tried to publish replication attempts, many had their papers accepted.

Further Information:

[How Replicable Are Links Between Personality Traits and Consequential Life Outcomes? The Life Outcomes of Personality Replication Project](https://sci-hub.ru/https://doi.org/10.1177/0956797619831612)

[Believe it or not: how much can we rely on published data on potential drug targets?](https://www.nature.com/articles/nrd3439-c1.pdf)

[Rigorous Large-Scale Educational RCTs Are Often Uninformative: Should We Be Concerned?](https://www.gwern.net/docs/sociology/2019-lortieforgues.pdf)

[A purely confirmatory replication study of structural brain-behavior correlations](https://sci-hub.ru/https://doi.org/10.1016/j.cortex.2014.11.019)

[On the reproducibility of science: unique identification of research resources in the biomedical literature](https://core.ac.uk/download/pdf/26001642.pdf)

[Raise standards for preclinical cancer research](https://www.nature.com/articles/483531a.pdf)

[Power failure: why small sample size undermines the reliability of neuroscience](https://www.nature.com/articles/nrn3475.pdf)

[Why Most Published Research Findings Are False](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124)

## Statistical Competence of Academics

**Academics are relatively lacking in their knowledge of data analysis and their ability to accurately interpret statistical information.**

[Even statisticians are not immune to misinterpretations of Null Hypothesis Significance Tests](https://onlinelibrary.wiley.com/doi/abs/10.1080/00207590244000250)

-   Looks at a sample of psychological researchers and applied statisticians

-   Finds that statisticians are not immune to misinterpretations of null hypothesis significance tests, and it is hard to conceive of consensus among statisticians due to this

-   Beyond this, problems can be seen in the misuses of judgmental adjustments that try to overcome the inherent shortcomings of null hypothesis significance tests.

[Blinding Us to the Obvious? The Effect of Statistical Training on the Evaluation of Evidence](https://www.researchgate.net/publication/283175190_Blinding_Us_to_the_Obvious_The_Effect_of_Statistical_Training_on_the_Evaluation_of_Evidence)

-   Researchers tend to evaluate statistical significance as dichotomous as opposed to continuous, which can lead to undervaluing of statistically insignificant evidence

[Robust misinterpretation of confidence intervals](https://pubmed.ncbi.nlm.nih.gov/24420726/)

-   Researchers are not much better than students in interpreting confidence intervals, and do so very poorly

[Contemporary Issues in the Analysis of Data: A Survey of 551 Psychologists](https://www.researchgate.net/publication/235363101_Contemporary_Issues_in_the_Analysis_of_Data_A_Survey_of_551_Psychologists)

-   Although experienced researchers can correctly answer complex data analysis questions at a chance better than average, they appear to misunderstand a lot of fundamental concepts in data analysis.

Further Information:

[Physician's use of probabilistic information in a real clinical setting](https://pubmed.ncbi.nlm.nih.gov/6457103/)

[Misinterpretations of Significance: A Problem Students Share with Their Teachers?](https://www.researchgate.net/publication/27262211_Misinterpretations_of_Significance_A_Problem_Students_Share_with_Their_Teachers)

[Beyond psychology: prevalence of p value and confidence interval misinterpretation across different fields](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/D1520CFBFEB2C282E93484057D84B6C6/S183449091900028Xa.pdf/beyond_psychology_prevalence_of_p_value_and_confidence_interval_misinterpretation_across_different_fields.pdf)

## Censorship in Academia

**There is a very strong anti right-wing bias in academia in terms of the endorsement of censoring right-wing beliefs. This appears to exist amongst both students and faculty.**

[Academic Freedom in Crisis: Punishment, Political Discrimination, and Self-Censorship](https://cspicenter.org/wp-content/uploads/2021/03/AcademicFreedom.pdf)

-   Uses large survey data for the US, Canada, and the UK

-   *Note: SSH refers to "social sciences and humanities", NAS refers to National Association of Scholars

##IMAGE

##IMAGE

##IMAGE

##IMAGE

##IMAGE

##IMAGE

##IMAGE

##IMAGE

##IMAGE

[What the Data Say About Student Support for Shout-downs, Blockades, and Violence](https://heterodoxacademy.org/blog/what-the-data-say-about-student-support-for-shout-downs-blockades-and-violence/)

##IMAGE

-   *Chart includes "always, sometimes, or rarely"

##IMAGE

##IMAGE

##IMAGE

##IMAGE

##IMAGE

##IMAGE

##IMAGE

[The Academic Mind in 2022: What Faculty Think About Free Expression and Academic Freedom on Campus](https://www.thefire.org/research-learn/academic-mind-2022-what-faculty-think-about-free-expression-and-academic-freedom)

-   Survey of 1491 faculty at four-year colleges and universities in the US

-   61% said a university professor should be free to express any of their ideas or convictions on any subject

-   More than half said speech should only be restricted where words are certain to incite physical violence

-   55% said students shouting down a speaker is never acceptable

-   92% said this about students using violence to stop a campus speech

-   50% of faculty believe an ideological litmus test that violates academic freedom is a justifiable requirement for a university job

-   A significant proportion of faculty ranging from 18% to 36% endorsed their college's administration launching a formal investigation into other faculty members for their controversial expression

-   34% of faculty said they often feel they can not express their opinions on a subject because of how students, colleagues, or the administration would respond

## Peer Review and Publication Bias

Peer reviewers tend to be biased against manuscripts which report results contrary to their theoretical perspective or political orientation, independent of the quality of the paper [(Abramowitz et al., 1975;](https://sci-hub.hkvisa.net/10.1111/j.1559-1816.1975.tb00675.x)  [(Mahoney, 1977)](https://link.springer.com/article/10.1007/BF01173636).

In the case of non-blinded peer review, the prominence of an author strongly biases whether a paper is accepted for peer review [(Ross et al., 2006;](https://sci-hub.ru/https://doi.org/10.1001/jama.295.14.1675)  [(Tomkins et al., 2017;](https://sci-hub.ru/https://doi.org/10.1073/pnas.1707323114)  [Huber et al., 2022)](https://files.catbox.moe/z0pp2y.pdf).

There tends to be low interrater reliability amongst peer reviewers [(Mahoney, 1977;](https://link.springer.com/article/10.1007/BF01173636)  [Rothwell, 2000;](https://sci-hub.ru/https://doi.org/10.1093/brain/123.9.1964)  [Bornmann et al., 2010)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0014331).

To test the effectiveness of peer review process in selecting for high-quality papers, John Bohannon submitted 304 versions of a fatally flawed paper to open-access journals. More than half of the journals accepted the paper [(Bohannon, 2013)](https://www.science.org/doi/10.1126/science.2013.342.6154.342_60).

Suggested solutions to the issue of peer review include blinding reviewers to the identity of authors, opening up peer review, and training peer reviewers, something that does not happen [(Smith, 2006)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1420798/).

There tends to exist a bias in favor of studies which are statistically significant, often with positive results, and against studies which fail to reject a null hypothesis [(Greenwald, 1975;](https://sci-hub.ru/https://doi.org/10.1037/h0076157)  [Atkinson et al., 1982;](https://sci-hub.se/https://doi.org/10.1037/0022-0167.29.2.189)  [Easterbrook et al., 1991;](https://www.thelancet.com/journals/lancet/article/PII0140-6736(91)90201-Y/fulltext)  [Sterling et al., 1995;](https://sci-hub.ru/https://doi.org/10.2307/2684823)  [Emerson et al., 2010;](https://sci-hub.ru/https://doi.org/10.1001/archinternmed.2010.406)  [Chopra et al., 2023)](https://academic.oup.com/ej/article-abstract/134/657/193/7238466?redirectedFrom=fulltext). Statistically significantly outcomes have a higher probability of being fully reported compared to non-significant outcomes [(Dwan et al., 2008)](https://sci-hub.se/https://doi.org/10.1371/journal.pone.0003081). Positive results tend to increase down the hierarchy of the sciences [(Fanelli, 2010)](https://sci-hub.ru/https://doi.org/10.1371/journal.pone.0010068). Positive results are becoming increasingly more common in published papers over time [(Fanelli, 2011)](https://link.springer.com/article/10.1007/s11192-011-0494-7), and positive results tend to receive significantly more citations than null or negative results, at least amongst applied disciplines and the biological sciences [(Fanelli, 2012)](https://link.springer.com/article/10.1007/s11192-012-0757-y). Positive results create publication bias in meta-analyses [(Song et al., 2009;](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2789098/)  [Kicinski, 2013;](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3868709/)  [Kicinski et al., 2015)](https://onlinelibrary.wiley.com/doi/10.1002/sim.6525).

Physicians ratings of a journal's quality are positively correlated with their impact factor [(Saha et al., 2003)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC141186/pdf/i0025-7338-091-01-0042.pdf). There is a statistically significant relationship between effect strength and journal quality measured by impact factor [(Murtaugh, 2002)](https://sci-hub.se/https://doi.org/10.1890/0012-9658(2002)083[1162:JQESAP]2.0.CO;2).

Single-blind peer reviewers are significantly more likely than double-blind counterparts to recommend for acceptance papers from famous authors, top universities, and top companies [(Tomkins et al., 2017)](https://sci-hub.se/https://doi.org/10.1073/pnas.1707323114).

While manuscripts appear to be improved by blinded peer reviewing [(Fletcher & Fletcher, 1997)](https://sci-hub.se/https://doi.org/10.1007/s11948-997-0015-5), research suggests that at least in social work few referees from prestigious or nonprestigious journals prepare reviews that are knowledgably, scientifically astute, or objective [(Epstein, 1990;](https://sci-hub.ru/https://doi.org/10.1177/016224399001500102)  [Schroter et al., 2008)](https://sci-hub.ru/https://doi.org/10.1258/jrsm.2008.080062). In research on road safety evaluation studies, there are very few statistically reliable differences in study validity between studies published in peer reviewed journals and studies not published in such journals [(Elvik, 1998)](https://sci-hub.ru/https://doi.org/10.1016/S0001-4575(97)00068-7).

Polling of university professors finds that there are many pernicious publication practices, including false criticisms and inferior expertise from peer reviewers [(Bradley, 1981)](https://sci-hub.ru/https://doi.org/10.3758/BF03333562).\
Across all disciplines, papers are more likely to support a tested hypothesis if their corresponding authors work in states that produce more academic papers per capita. This suggests that competitive academic environments may increase scientists' bias [(Fanelli, 2010)](https://sci-hub.se/https://doi.org/10.1371/journal.pone.0010271).

</div>
